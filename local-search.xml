<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>万人大群技术实践总结</title>
    <link href="/2024/08/07/%E4%B8%87%E4%BA%BA%E5%A4%A7%E7%BE%A4%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5%E6%80%BB%E7%BB%93/"/>
    <url>/2024/08/07/%E4%B8%87%E4%BA%BA%E5%A4%A7%E7%BE%A4%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<h1 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h1><h2 id="为什么做万人大群？"><a href="#为什么做万人大群？" class="headerlink" title="为什么做万人大群？"></a>为什么做万人大群？</h2><h3 id="1-1-解决系统稳定性问题"><a href="#1-1-解决系统稳定性问题" class="headerlink" title="1.1 解决系统稳定性问题"></a>1.1 解决系统稳定性问题</h3><p>目前生产存在一百多个五百人以上的大群，在群比较活跃的情况下，系统 CPU 和内存指标会产生较大毛刺，影响系统稳定性。</p><h3 id="1-2-用户有大群需求"><a href="#1-2-用户有大群需求" class="headerlink" title="1.2 用户有大群需求"></a>1.2 用户有大群需求</h3><p>HR 等部门存在一些对于大群的需求，需要满足大量用户同时在线聊天或抢红包的场景。</p><h2 id="万人群为何不能简单通过水平扩容解决？"><a href="#万人群为何不能简单通过水平扩容解决？" class="headerlink" title="万人群为何不能简单通过水平扩容解决？"></a>万人群为何不能简单通过水平扩容解决？</h2><h3 id="2-1-写扩散设计问题"><a href="#2-1-写扩散设计问题" class="headerlink" title="2.1 写扩散设计问题"></a>2.1 写扩散设计问题</h3><p>原有的写扩散设计中，消息需要按照 1:10000 的比例进行存储，这将导致服务端和存储（如数据库、缓存等）之间的 QPS 和网络流量非常高。简单地通过水平扩容来增加服务器数量并不能解决这个问题。</p><h3 id="2-2-下游处理问题"><a href="#2-2-下游处理问题" class="headerlink" title="2.2 下游处理问题"></a>2.2 下游处理问题</h3><p>对于下游的订阅转发和离线推送，按照常规的消息处理流程，将会产生大量的子任务，对系统的吞吐量要求极高。仅仅通过水平扩容去解决问题，需要消耗大量服务器资源。因此，需要采取其他策略来解决万人群的问题。</p><h1 id="二、系统架构"><a href="#二、系统架构" class="headerlink" title="二、系统架构"></a>二、系统架构</h1><h2 id="IM-消息系统架构"><a href="#IM-消息系统架构" class="headerlink" title="IM 消息系统架构"></a>IM 消息系统架构</h2><p>系统交互图：TrippalCore 系统交互图</p><h1 id="三、实现方案"><a href="#三、实现方案" class="headerlink" title="三、实现方案"></a>三、实现方案</h1><h2 id="1-引入读扩散机制"><a href="#1-引入读扩散机制" class="headerlink" title="1. 引入读扩散机制"></a>1. 引入读扩散机制</h2><p>现有 IM 群消息系统采用的是写扩散的机制，即每发送一条消息都会给所有群成员写一条数据。这种机制的好处是查询逻辑简单，只需从自身存储的数据队列或表中读取一次。然而，随着群成员人数的增加，消息分发的数量会被放大，例如在万人群中，每发送 1 条消息，��务端消息同步和存储的量就是 10000，消息数量被放大了一万倍。</p><p>对于普通群聊来说，一条消息只会产生一次，但会被读取多次，是典型的读多写少的场景，因此适合采用写扩散的模式。然而，对于大群来说，就需要引入读扩散的模式，即消息只需写一次，相比写扩散的模式，能够大大降低消息写入次数。不过，读扩散模式的缺点是查询会变得复杂。</p><h3 id="读扩散与写扩散机制下的消息存储差异"><a href="#读扩散与写扩散机制下的消息存储差异" class="headerlink" title="读扩散与写扩散机制下的消息存储差异"></a>读扩散与写扩散机制下的消息存储差异</h3><p>当采用读扩散的消息存储方式后，无法像写扩散一样通过一次 Redis 查询获得完整的消息列表。在读扩散模式下，需要对不同类型的消息进行聚合，包括群公共消息、个人消息和个人删除消息等。此外，还需要关注与用户相关的其他数据，例如判断用户是否被踢出群聊以及被踢出的时间���。这些额外的数据需要与消息数据进行关联，以便在查询时进行判断和过滤。总的来说，读扩散模式下的消息存储方式相对复杂，需要进行更多的数据聚合和关联操作，以满足不同类型的查询需求。</p><h3 id="读扩散机制下的缓存差异"><a href="#读扩散机制下的缓存差异" class="headerlink" title="读扩散机制下的缓存差异"></a>读扩散机制下的缓存差异</h3><p>引入读扩散机制后，对业务处理层 SOA 服务的整体结构进行了重构，具体设计如下：</p><ul><li>读扩散 db 与查询接口：读扩散 db 设计与相关接口</li><li>读扩散缓存结构：读扩散缓存方案</li></ul><h2 id="2-群成员本地缓存"><a href="#2-群成员本地缓存" class="headerlink" title="2. 群成员本地缓存"></a>2. 群成员本地缓存</h2><p>在 IM 消息系统中，消息分发与存储时都需要查询群成员列表，万人大群的群成员列表，需要的存储空间较大（一个成员占用 200 字节，万人群约占用 2MB）。如果将这些数据存储在 Redis 中，会导致出现 bigKey 问题。因此，我们对大群实现了本地群成员缓存的方案，��时从数据库中拉取数据，并通过监听 qmq 消息对增量数据进行更新，这样可以避免 bigKey 问题的发生��</p><h2 id="3-聚合已读上报"><a href="#3-聚合已读上报" class="headerlink" title="3. 聚合已读上报"></a>3. 聚合已读上报</h2><p>未读数统计的压力会随着群人数和发消息频率的增长而成倍上升。以万人群为例，假设这个群平均每秒有 5 个人发言，那么每秒针对未读数的变更 QPS 就是 5 万。尽管端上有聚合刷新逻辑，但时间间隔只有 200 毫秒，即每个用户每秒最多还是会刷新 5 次。在万人群中，同时在线查看消息时，已读上报的 QPS 依然会达到 5 万。因此，需要对已读上报进行合并，以给定的频次更新数据库和 Redis，从而减轻系统的负载压力。</p><h2 id="4-增加限流措施"><a href="#4-增加限流措施" class="headerlink" title="4. 增加限流措施"></a>4. 增加限流措施</h2><p>为了保证服务的稳定性，增加了限流机制，主要考虑个人维度和群维度进行限流。消息限流方案，具体措施如下：</p><ol><li>设置时间窗口为 10 秒，该时间窗口是一个滑动窗口。</li><li>在每次发送消息之前，检查当前时间之前的 10 秒内发送的消息总量是否超过设定的阈值。</li><li>如果消息总量超过阈值，将限制该用户或群组在该时间窗口内继续发送消息。</li></ol><p>通过以上限流措施，可以防止个人或群组在短时间内发送过多的消息，保证消息发送的平滑性，避免瞬时的 QPS 过高的问题。</p><h2 id="5-旁路服务优化"><a href="#5-旁路服务优化" class="headerlink" title="5. 旁路服务优化"></a>5. 旁路服务优化</h2><p>消息分发和存储后会通过 qmq 的方式通知到旁路服务即订阅转发和离线推送服务，所以对于万人大群来说，子任务的 QPS 也是万级的，以现有的服务器资源来处理会导致 qmq 大量积压，也会导致 qmq 平台压力激增，因此不仅需要提升我们自身系统的吞吐能力，还要关注 qmq 平台的风险。</p><h3 id="5-1-降低-qmq-平台风险"><a href="#5-1-降低-qmq-平台风险" class="headerlink" title="5.1 降低 qmq 平台风险"></a>5.1 降低 qmq 平台风险</h3><ol><li>通知 qmq 平台将 trippal 和 im+ 相关 qmq 分别单独部署；</li><li>将 trippal 大流量特定主题临时迁移到 log 集群；</li><li>qmq 平台的处理能力与磁盘 I&#x2F;O 有关，对大流量主题下的消息进行瘦身，将消息体从 4k 缩减到 2k；</li></ol><p>对于不能进行缩减内容的主题，可以采用 qmq 框架提供的压缩功能。</p><h3 id="5-2-优化订阅转发和离线推送服务"><a href="#5-2-优化订阅转发和离线推送服务" class="headerlink" title="5.2 优化订阅转发和离线推送服务"></a>5.2 优化订阅转发和离线推送服务</h3><ol><li><strong>批量消费</strong>：100012835（订阅转发服务）和 100023553（离线推送服务）将 qmq 消息的消费方式改为批量消费，以加快 qmq 消息的处理。</li><li><strong>减少 SOA 路由时间</strong>：100012835 中将用户信息查询由 SOA 调用的方式改为直接从 Redis 读取，通过 mget 一次性查询即可，节省了 SOA 路由时间。</li><li><strong>支持批量查询</strong>：100023553 需要查询用户在线状态等数据，相关接口都需要支持批量查询，以提高查询效率。</li></ol><table><thead><tr><th>应用</th><th>接口</th><th>功能</th></tr></thead><tbody><tr><td>100012833</td><td>batchgetuserblockconfig</td><td>SOA 服务：黑名单查询</td></tr><tr><td>100023646</td><td>batchgetusersonline</td><td>私有云：用户各端状态查询</td></tr><tr><td>100029681</td><td>batchgetusersonline</td><td>阿里云：用户各端状态查询</td></tr><tr><td>100028428</td><td>batchgetuseronlinestatus</td><td>私有云中转服务：各端状态查询</td></tr><tr><td>100028430</td><td>batchgetuseronlinestatus</td><td>阿里云中转服务：各端状态查询</td></tr></tbody></table><ol start="4"><li><strong>下线无效调用</strong>：压测过程中发现下游 push 服务的压力很大，经排查发现有 50% 的调用是无效调用，无效调用删除后，减轻了下游 push 服务的压力。</li><li><strong>解决线程阻塞的问题</strong>：压测时发现系统线程存在 block 的情况，为提高系统的资源利用率，分析具体原因后逐一解决。</li></ol><h3 id="5-3-推动上游系统优化"><a href="#5-3-推动上游系统优化" class="headerlink" title="5.3 推动上游系统优化"></a>5.3 推动上游系统优化</h3><p>通过分析日志，发现离线推送服务与 trippal 业务服务，存在重复调用查询用户各端在线状态接口的情况，推动上游做技术改造，去除无效调用，简化了系统流程。</p><p>通过以上措施的应用，提高了系统的吞吐能力，在不扩容的情况下，使订阅转发和离线推送系统的处理能力提升了 2.4 倍左右。</p><h2 id="6-trippal-多账号消息分发重构"><a href="#6-trippal-多账号消息分发重构" class="headerlink" title="6. trippal 多账号消息分发重构"></a>6. trippal 多账号消息分发重构</h2><p>随着业务的发展，trippal 面向的受众不只是携程员工，还接入了许多供应商公司，因此底层消息系统需要处理多账户员工的消息分发，在做万人大群项目时，发现原有多账号消息分发的架构不合理，无法支撑万人大群的业务，因此对该部分进行了重构。</p><h3 id="6-1-多公司组账号查询时机不合理"><a href="#6-1-多公司组账号查询时机不合理" class="headerlink" title="6.1 多公司组账号查询时机不合理"></a>6.1 多公司组账号查询时机不合理</h3><p>原有逻辑将多账号的查询放在了 TCPServer 中，但 dispatcher 调用 TCPServer 是广播模式，造成每一台 TCPServer 机器都需要去查询群成员的多账号信息，人为将查询流量放大了数十倍。</p><h3 id="6-2-多账号缓存数据结构不合理"><a href="#6-2-多账号缓存数据结构不合理" class="headerlink" title="6.2 多账号缓存数据结构不合理"></a>6.2 多账号缓存数据结构不合理</h3><p>查询一个用户的账号信息，需要 4 次 Redis 操作，逻辑过于复杂；改造���，不仅查询某位用户的账号信息只需一次 get，批量查询多个用户账号信息也只需要一次 mget。</p><p>原有的结构，查询 100 个用户的账号信息，会给 Redis 带来 4000（10*4*100）次的访问，现在只需要一次，所以 TCPServer 的多账号逻辑不再成为万人大群的瓶颈。</p><h3 id="6-3-云-notify-后发送未读提醒消息重复"><a href="#6-3-云-notify-后发送未读提醒消息重复" class="headerlink" title="6.3 云 notify 后发送未读提醒消息重复"></a>6.3 云 notify 后发送未读提醒消息重复</h3><p>目前公司存在部分用户有多个公司组账号的情况，其中某员工有 192 个多账号信息，该用户的某一账号收到一条消息后，会查询其有建立长链接的端，然后发一条通知消息，客户端收到通知后会通过 http 接口拉取未读数。原有的逻辑中，每收到一条消息，会导致未读数接口被调用 192 次，每次查询 192 个账号的未读数，对 Redis 的访问是 192*192 次，瞬间形成了对 Redis 将近 4 万 QPS 的调用。</p><p>经过排查，发现该账号调用云 notify 接口 192 次，在接口的处理逻辑中，又查询了每个账号的多账号信息，所以导致提醒消息发了 192 次，新的流程只会调用 notify 接口一次，所以 Redis 不会再出现这种流量尖峰问题。</p><h2 id="7-自动升级机制"><a href="#7-自动升级机制" class="headerlink" title="7. 自动升级机制"></a>7. 自动升级机制</h2><p>完成了上述改造后，系统具备了承载大群的能力，还需要考虑如何新增读扩散群的问题，以及历史大群如何迁移到读扩散机制。因为生产现存的大群都是写扩散的，而且整个迁移过程需要让用户无感，因此增加了以下迁移与自动升级流程：</p><ol><li><strong>MTP 页面新增创建大群按钮</strong>：自动创建读扩散的群。</li><li><strong>MTP 群成员上限设置页面</strong>：配置群成员上限时，会自动触发检测与升级。</li></ol><p>触发升级后，先升级为双写状态，增量的新消息会同时写入读扩散和写扩散的数据存储中，再将历史的最新 1000 条群消息写入读扩散的 db 和缓存中，写入完毕自动将群设置为读扩散群，后续写入和查询均直接走读扩散流程。</p><h1 id="四、改动范围与影响"><a href="#四、改动范围与影响" class="headerlink" title="四、改动范围与影响"></a>四、改动范围与影响</h1><h2 id="1-改动点"><a href="#1-改动点" class="headerlink" title="1. 改动点"></a>1. 改动点</h2><p>本项目的改动几乎涉及了 trippalCore 相关的所有应用，以及所有核心流程，具体��计如下：</p><table><thead><tr><th>统计类别</th><th>数量（个）</th></tr></thead><tbody><tr><td>表</td><td>2</td></tr><tr><td>缓存 key</td><td>11</td></tr><tr><td>相关 SQL</td><td>29</td></tr><tr><td>应用数量</td><td>10</td></tr><tr><td>接口数量</td><td>30+</td></tr></tbody></table><h2 id="2-影响面"><a href="#2-影响面" class="headerlink" title="2. 影响面"></a>2. 影响面</h2><p>该项目影响到了消息在 trippalCore 系统中流转的整个生命周期，不仅影响��增的读扩散的群，因为重构了众多流程，原有写扩散的流程也会受到影响。具体包括以下几个方面：</p><ol><li>大群消息的收发，以及其他群成员消息的推送；</li><li>大群消息的撤回与删除，其中删除是仅删除自身的消息而不是删除群消息；</li><li>拉取会话列表：同时拉取最新的读扩散和写扩散的会话再做聚合；</li><li>展示会话最新一条消息，拉取会话列表时需要展示；</li><li>查询大群会话消息：支持轮询最新消息，以及查询历史消息（包括进群前消息）；</li><li>未读数统计：单个会话未读数统计与总未读数统计，以及多公司组账号未读数统计；</li><li>离线推送消息：用户各端长连接断链后，通过厂商通道将消息推到客户端；</li><li>下游其他业务逻辑，T2O 咨询，聊天记录搜索等，通过订阅消息 qmq 的方式完成。</li></ol><h1 id="五、测试与灰度"><a href="#五、测试与灰度" class="headerlink" title="五、测试与灰度"></a>五、测试与灰度</h1><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>在自测项目中，除了保证读扩散机制的业务逻辑正确，还需要验证整个消息系统的可靠性与稳定性。为了达到这个目标，做了以下工作：</p><h3 id="读扩散测试方案"><a href="#读扩散测试方案" class="headerlink" title="读扩散测试方案"></a>读扩散测试方案</h3><ol><li><strong>功能验证</strong>：功能验证分为两部分，一部分是基于接口的测试验证，另一部分是基于客户端展示的验证，除了验证基本功能外，还需关注缓存数据与 db 数据的一致性。</li><li><strong>全链路压测</strong>：进行多轮的全链路压测，模拟真实的业务场景，以验证系统在高并发负载下的性能。通过压测不仅发现了服务端的瓶颈，也发现了客户端存在的问题，从而推动服务端到客户端全链路的性能优化。</li></ol><h2 id="灰度"><a href="#灰度" class="headerlink" title="灰度"></a>灰度</h2><p>因为将整个项目拆分成���个小项目，每一阶段都有明确的目标与灰度机制，项目上线后运转良好，得益于以下机制：</p><ol><li><strong>开关控制</strong>：项目的每一阶段都有配置开关进行灰度，分别有用户维度和群维度的开关，通过配置这些开关，可以更加灵活地控制灰度的进度；</li><li><strong>持续优化</strong>：切流以后，通过查询 db 访问日志和缓存命中率等，分析各种场景的查询是否合理，缓存是否应该命中，持续优化系统。</li></ol><h3 id="读扩散群运转问题分析"><a href="#读扩散群运转问题分析" class="headerlink" title="读扩散群运转问题分析"></a>读扩散群运转问题分析</h3><table><thead><tr><th>表</th><th>优化内容</th><th>结果</th></tr></thead><tbody><tr><td>group_conversation_message</td><td>优化读扩散查询未读数逻辑，该场景下 SQL 的执行次数减少了 90%</td><td>经过多个场景下的优化，关于该表的访问减少了四分之一</td></tr><tr><td>muc_message</td><td>优化读扩散查询未读数逻辑，该场景下 SQL 的执行次数减少了 90%</td><td>经过多个场景下的优化，关于该表的访问减少了四分之一</td></tr></tbody></table><h1 id="六、收获"><a href="#六、收获" class="headerlink" title="六、收获"></a>六、收获</h1><ol><li><strong>提升系统的吞吐能力</strong>：通过引入读扩散���制，以及对系统进行优化，提高了系统的吞吐能力。在不扩容的情况下，整个消息系统的处理能力是原来的 2-3 倍，这使得系统可以更好地应对高并发场景，提高了系统的稳定性和可靠性。</li><li><strong>支持万人群在线聊天，千人群在线抢红包的业务场景</strong>：这为 trippal 用户提供了更好的使用体验，生产有经过三次验证，服务端都能够轻松负载，验证了整套机制的可行性。</li><li><strong>节约 db 存储</strong>：目前超过 500 人的大群有 130 个，其中超过 1000 人的大群有 50 个，按大群平均每天会发送 10 条消息来算，通过读扩散的方式每天可以减少 100 万条消息数据的存储。</li></ol>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/08/06/MySQL%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB%E5%88%B0OceanBase/"/>
    <url>/2024/08/06/MySQL%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB%E5%88%B0OceanBase/</url>
    
    <content type="html"><![CDATA[<p>Mysql本身的不足：</p><ol><li><p>MySQL 的 online DDL 带来的稳定性风险</p></li><li><p>基于 binlog 复制的多节点读写分离会有数据一致性问题</p></li><li><p>单表数据量承载能力有限，随着业务上升，消息表的数据量一直增加</p></li></ol><p>OB优势：</p><p>1、因为 OB 的存储引擎使用了类 LSM Tree 设计，表的 scheme 也支持多个版本，所以在 在线DDL 已经不是问题，秒级即可完成并且不会锁表，可以放心的做此类操作。</p><p>2、使用优化的paxos协议结合物理日志复制保证多数派的数据一致性， 也就是三副本情况下强保证至少两个副本数据一致性，使用 OB 保证了 RTO＜30s，满足业务的数据一致性的要求。</p><p>3、以 IM 业务为例，我们群组消息表保存两个月数据占用存储空间800G 左右，基本触达当前配置下的 MySQL 单表上线；同样的数据迁移到 OB 后数据量在200G 左右。实际测试下来IM主库压缩率在1&#x2F;3左右</p><p>4、OB是share nothing 架构，每个副本都是对等节点，多数派副本可以保持一致性，从根本上保证主备切换是一个安全的操作，系统宕机30s内可以自动发现和切换到具备完整数据的副本上，保证服务连续可用</p><p>OB的不足：</p><p>1、分区建的设计需要根据业务特性定义，开发需要根据业务设计合理的分区建，否则会影响查询性能</p><p>2、OB合并刷盘机制（会在业务低峰期，可配置）会影响插入和查询时间，大概10ms左右</p><p>Mysql和OB部署架构图</p><p>1、Mysql MHA Cluster部署</p><p><img src="/source/_picture/image2022-3-30_15-37-38.png" alt="image-20240805155101049"></p><p>2、OB三机房部署</p><p>相关压测性能数据指标</p><ol><li>Mysql集群和ob集群分别通过 sysbench 导入 16 张表，每张表有 1000 万行数据。</li></ol><table><thead><tr><th><strong>read_write</strong></th><th><strong>mysql 5.7.23</strong></th><th><strong>ob(16</strong>张表都在单机房）**</th><th><strong>ob(16</strong>张表部署在双机房）**</th><th><strong>ob(16</strong>张表部署在三机房）**</th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td><strong>Threads</strong></td><td><strong>QPS</strong></td><td><strong>95%  latency (ms)</strong></td><td><strong>QPS</strong></td><td><strong>95%  latency (ms)</strong></td><td><strong>QPS</strong></td><td><strong>95% latency (ms)</strong></td><td><strong>QPS</strong></td><td><strong>95% latency (ms)</strong></td></tr><tr><td>150</td><td>78268.66</td><td>45.79</td><td>76760</td><td>49</td><td>92685</td><td>40</td><td>89922</td><td>40</td></tr><tr><td>300</td><td>85187.99</td><td>101.13</td><td>85336</td><td>124</td><td>121662</td><td>86</td><td>145456</td><td>66</td></tr><tr><td>600</td><td>87068.84</td><td>569.67</td><td>104655</td><td>184</td><td>137061</td><td>168</td><td>177557</td><td>93</td></tr><tr><td>1200</td><td>91627.88</td><td>977.74</td><td>115891</td><td>277</td><td>146951</td><td>308</td><td>197960</td><td>241</td></tr><tr><td>1500</td><td>85861.23</td><td>1235.62</td><td>113291</td><td>387</td><td>149243</td><td>430</td><td>202863</td><td>349</td></tr></tbody></table><p>2、对比结果分析：</p><p>对于混合读写的情况，在并发超过100以上时OB部署多机房的qps高于MySQL，响应时间和MySQL差不多，随着并发数量增加，OB的qps提升明显，响应时间也比Mysql低很多。</p><p>目前线上的性能指标</p><p>1、需要通过OCP（OB的监控管理工具）监控，目前还没有和hickwall打通</p><p>2、响应时间（单位us）基本在1ms左右</p><p><img src="/source/_picture/image2022-3-29_10-32-48.png" alt="image2022-3-29_10-32-48"></p><p><img src="/source/_picture/image2022-3-29_10-37-36.png" alt="image-20240805154948720"></p><p>1、业务迁移</p><p>迁移原则：</p><p>数据完整性和准确：保证数据不丢、不错；</p><p>迁移平滑和迅速：服务敏感度，不停服；</p><p>可回滚：遇到问题可随时切回mysql</p><p>1）数据同步</p><p>应用双写同步mysql数据到ob集群，DBA按照时间戳去对比mysql和ob两边数据的一致性，做数据一致性校验</p><p>2）读写验证</p><p>验证应用访问MYSQL和OB集群可以得到相同的结果，验证业务访问的准确性</p><p>可以根据业务需要迁移部分读流量到OB 集群</p><p>3）灰度切换</p><p>调整双写开发</p><p>将部分非核心业务的库表写操作迁移至OB集群，并双写至MYSQL，保证出问题，随时回滚</p><p>当业务访问长时间正常，可以增加切换流量，进行灰度切换，建议观察一段时间，至少一个月</p><p>4）迁移完成</p><p>流量全部迁移完成，继续保持OB集群反向同步至MYSQL，继续观察一段时间，没有问题后，关闭反向双写</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
